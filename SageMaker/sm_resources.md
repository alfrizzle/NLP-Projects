# SageMaker Resources

## Helpful Diagrams
* https://blog.codecentric.de/en/2020/01/aws-sagemaker-data-handling/
* https://github.com/philschmid/huggingface-sagemaker-workshop-series/blob/main/workshop_1_getting_started_with_amazon_sagemaker/lab_1_default_training.ipynb

## Using PyTorch in SM
* https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html
* https://aws.amazon.com/blogs/machine-learning/bring-your-own-model-with-amazon-sagemaker-script-mode/
* https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-script-mode/sagemaker-script-mode.ipynb

### Distributed Data Parallel (DDP)
* https://sagemaker-examples.readthedocs.io/en/latest/training/distributed_training/index.html#pytorch-distributed
* https://sagemaker.readthedocs.io/en/stable/api/training/smd_data_parallel_use_sm_pysdk.html#sdp-api-docs-launch-training-job
* https://aws.amazon.com/blogs/aws/managed-data-parallelism-in-amazon-sagemaker-simplifies-training-on-large-datasets/
* https://github.com/huggingface/notebooks/blob/main/sagemaker/03_distributed_training_data_parallelism/sagemaker-notebook.ipynb
* https://jdhao.github.io/2019/11/01/pytorch_distributed_training/
* https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html
* https://pytorch.org/docs/stable/_modules/torch/utils/data/distributed.html#DistributedSampler
* https://pytorch.org/docs/stable/distributed.html
* https://huggingface.co/transformers/v4.4.2/sagemaker.html

## Available Deep Learning Containers (DLCs)
* https://github.com/aws/deep-learning-containers/blob/master/available_images.md
* https://github.com/aws/deep-learning-containers

## SageMaker Huggingface Workshop Series
* https://github.com/philschmid/huggingface-sagemaker-workshop-series

## Use Checkpoints in Amazon SageMaker
* https://docs.aws.amazon.com/sagemaker/latest/dg/model-checkpoints.html
* https://huggingface.co/docs/sagemaker/train#training-output-management
* https://huggingface.co/docs/sagemaker/train#spot-instances
