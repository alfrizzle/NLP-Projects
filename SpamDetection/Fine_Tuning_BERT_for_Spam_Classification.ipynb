{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Fine-Tuning BERT for Spam Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfrizzle/NLP-Projects/blob/master/SpamDetection/Fine_Tuning_BERT_for_Spam_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFOTiqrtNvyy"
      },
      "source": [
        "# Install Transformers Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwKJMDtMogyz",
        "outputId": "65b03be9-3eb4-4d59-b61d-1ebd4aa58dc2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hkhc10wNrGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c48094e3-64d0-43e0-986e-444f9546e36c"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4giRzM7NtHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32ab3d89-b379-4439-c34a-a0f44d96f122"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_curve, precision_recall_curve\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "# specify GPU\n",
        "# device = torch.device(\"cuda\")\n",
        "# print(device)\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFOZr4-Zo6oI",
        "outputId": "850e6ce5-4845-44ee-8be0-f9709b5d006f"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/BERT_Practice/spam_detection')\n",
        "!pwd"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/BERT_Practice/spam_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKd-Tj3hOMsZ"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwJrQFQgN_BE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8666b059-0079-496f-ea87-9de28b0f7ee4"
      },
      "source": [
        "df = pd.read_csv(\"./data/spamdata_v2.csv\")\n",
        "df.head()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               text\n",
              "0      0  Go until jurong point, crazy.. Available only ...\n",
              "1      0                      Ok lar... Joking wif u oni...\n",
              "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      0  U dun say so early hor... U c already then say...\n",
              "4      0  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzPPOrVQWiW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ffa96eb-531e-415f-bc83-d4f37548ff80"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6npMk9vpbZQ",
        "outputId": "802a4f83-3076-489e-f299-aab15114952a"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['label', 'text'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "676DPU1BOPdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1816adf4-933b-4062-f516-61f83238815c"
      },
      "source": [
        "# check class distribution\n",
        "print(df['label'].value_counts(),'\\n')\n",
        "print(df['label'].value_counts(normalize = True))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    4825\n",
            "1     747\n",
            "Name: label, dtype: int64 \n",
            "\n",
            "0    0.865937\n",
            "1    0.134063\n",
            "Name: label, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGVieKsD_-Du"
      },
      "source": [
        "# Random Undersampling (aka Downsampling)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7VcjrAXA7my"
      },
      "source": [
        "https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW3Xw1_f_QS8"
      },
      "source": [
        "# Class count\n",
        "count_class_0, count_class_1 = df.label.value_counts()\n",
        "\n",
        "# Divide by class\n",
        "df_class_0 = df[df['label'] == 0]\n",
        "df_class_1 = df[df['label'] == 1]"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsqrfWsiAFFJ",
        "outputId": "b59cce59-6090-4adc-e4d8-ac32ed90b5b1"
      },
      "source": [
        "df_class_0_under = df_class_0.sample(count_class_1)\n",
        "df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
        "\n",
        "print('Random under-sampling:')\n",
        "print(df_test_under.label.value_counts())"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random under-sampling:\n",
            "1    747\n",
            "0    747\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "Ylnm2R1LANit",
        "outputId": "6e48533a-f40e-4914-c8f2-e78f146c8004"
      },
      "source": [
        "df_test_under.label.value_counts().plot(kind='bar', title='Count (Label)');"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKfWnApvOoE7"
      },
      "source": [
        "# Split train dataset into train, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfhSPF5jOWb7"
      },
      "source": [
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df_test_under['text'], df_test_under['label'], \n",
        "                                                                    random_state=2020, \n",
        "                                                                    test_size=0.2, \n",
        "                                                                    stratify=df_test_under['label'])\n",
        "\n",
        "# we will use temp_text and temp_labels to create validation and test set\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=2020, \n",
        "                                                                test_size=0.2, \n",
        "                                                                stratify=temp_labels)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7hsdLoCO7uB"
      },
      "source": [
        "# Import BERT Model and BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1kY3gZjO2RE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8643dd6e-1f6b-4c8b-9344-b9f3a619f119"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# bert = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zOKeOMeO-DT"
      },
      "source": [
        "# sample data\n",
        "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n",
        "\n",
        "# encode text\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAH73n39PHLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac69060a-79fb-403c-8af5-37b3d4554f2b"
      },
      "source": [
        "# output\n",
        "print(sent_id)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wIYaWI_Prg8"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKwbpeN_PMiu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "261dda0f-a830-4a6a-b3b5-eb3da7b4ea51"
      },
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f08c3f22e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXcswEIRPvGe"
      },
      "source": [
        "max_seq_len = 25"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk5S7DWaP2t6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc168d11-f529-4267-f7bb-1a72a5c64c25"
      },
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wsm8bkRZQTw9"
      },
      "source": [
        "# Convert Integer Sequences to Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR-lXwmzQPd6"
      },
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "# for validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov1cOBlcRLuk"
      },
      "source": [
        "# Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUy9JKFYQYLp"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2HZc5ZYRV28"
      },
      "source": [
        "# Freeze BERT Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHZ0MC00RQA_"
      },
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7ahGBUWRi3X"
      },
      "source": [
        "# Define Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3iEtGyYRd0A"
      },
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBAJJVuJRliv"
      },
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taXS0IilRn9J"
      },
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9CDpoMQR_rK"
      },
      "source": [
        "# Find Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izY5xH5eR7Ur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c92f9d5c-ef5b-42dc-d8d4-3cd5634aa9b3"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
        "\n",
        "print(class_wts)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.00083752 0.99916388]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1WvfY2vSGKi"
      },
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 10"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My4CA0qaShLq"
      },
      "source": [
        "# Fine-Tune BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rskLk8R_SahS"
      },
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGXovFDlSxB5"
      },
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KZEgxRRTLXG"
      },
      "source": [
        "# Start Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDot8MveyLbt",
        "outputId": "0c3a4661-05eb-4457-9f54-7d2e20e81334"
      },
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.673\n",
            "Validation Loss: 0.460\n",
            "\n",
            " Epoch 2 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.407\n",
            "Validation Loss: 0.440\n",
            "\n",
            " Epoch 3 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.359\n",
            "Validation Loss: 0.346\n",
            "\n",
            " Epoch 4 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.363\n",
            "Validation Loss: 0.394\n",
            "\n",
            " Epoch 5 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.249\n",
            "Validation Loss: 0.227\n",
            "\n",
            " Epoch 6 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.239\n",
            "Validation Loss: 0.174\n",
            "\n",
            " Epoch 7 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.229\n",
            "Validation Loss: 0.171\n",
            "\n",
            " Epoch 8 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.195\n",
            "Validation Loss: 0.173\n",
            "\n",
            " Epoch 9 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.201\n",
            "Validation Loss: 0.749\n",
            "\n",
            " Epoch 10 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.281\n",
            "Validation Loss: 0.153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yrhUc9kTI5a"
      },
      "source": [
        "# Load Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OacxUyizS8d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65e32c7f-f018-458b-9b73-921540eb9da5"
      },
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4SVftkkTZXA"
      },
      "source": [
        "# Get Predictions for Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZl0SZmFTRQA"
      },
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J10sipyDCIEB",
        "outputId": "c7c142c1-ecda-4901-9884-6a5383cbfa2b"
      },
      "source": [
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        30\n",
            "           1       1.00      1.00      1.00        30\n",
            "\n",
            "    accuracy                           1.00        60\n",
            "   macro avg       1.00      1.00      1.00        60\n",
            "weighted avg       1.00      1.00      1.00        60\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "JLuXo0apCNvX",
        "outputId": "1f8b351e-ce22-4537-b94a-d05f0cfda5ae"
      },
      "source": [
        "# confusion matrix\n",
        "pd.crosstab(test_y, preds)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0   0   1\n",
              "row_0        \n",
              "0      30   0\n",
              "1       0  30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms1ObHZxTYSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de435257-728e-472b-b60e-d42eb9a67976"
      },
      "source": [
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98       724\n",
            "           1       0.81      0.94      0.87       112\n",
            "\n",
            "    accuracy                           0.96       836\n",
            "   macro avg       0.90      0.95      0.92       836\n",
            "weighted avg       0.97      0.96      0.96       836\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqzLS7rHTp4T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "1f471f0f-b7b8-4728-9a37-1407638d7daf"
      },
      "source": [
        "# confusion matrix\n",
        "pd.crosstab(test_y, preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>700</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0    0    1\n",
              "row_0          \n",
              "0      700   24\n",
              "1        7  105"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpX1uTwjUPY6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}